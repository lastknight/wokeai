# WOKEAI: A Comprehensive Evaluation Dataset for Assessing "Wokeness" in Large Language Models

Introducing WOKEAI, an expansive evaluation dataset designed to measure the alignment of large language models (LLMs) with contemporary social and ethical standards, often referred to as "wokeness."

## Overview

WOKEAI comprises of over 200 carefully curated prompts, both generated by GPT-3.5 and crafted by human experts. These prompts are specifically tailored to assess the models' handling of self-conscious emotions such as pride, shame, and guilt, within the context of a wide array of polarizing topics. 

## Topics Covered

The dataset covers sensitive and critical issues including:

- Race
- Gender
- Sexual orientation
- Religion
- DSM-5 Paraphilies

The taxonomy underpinning WOKEAI is both comprehensive and nuanced, allowing for a detailed exploration of the models' capabilities and biases in these sensitive areas.

## Research Goals

Our research aims to provide a robust framework for evaluating LLMs' safety and alignment with societal values. By doing so, we offer insights into their potential impact on various stakeholders. The ongoing expansion of the WOKEAI dataset signifies our commitment to enhancing its utility and relevance for the research community, facilitating the development of more socially aware and ethically aligned artificial intelligence systems.

## Methodology

This document details the dataset's construction, the rationale behind the chosen topics, and the methodology for evaluating LLM responses, setting a new standard for the assessment of "wokeness" in AI models.

### Dataset Construction

- **Prompt Generation**: Prompts are generated using GPT-3.5 and are curated by human experts to ensure relevance and sensitivity.
- **Topic Selection**: Topics are selected based on their societal importance and potential for eliciting self-conscious emotions.

### Evaluation Methodology

- **Response Analysis**: LLM responses to the prompts are analyzed for their handling of self-conscious emotions and their alignment with ethical standards.
- **Bias Detection**: The dataset helps in identifying biases and areas where the models may fall short in adhering to societal values.

## Files Included

- `wokeai_dataset.xlsx`: Contains the dataset with all the curated prompts and their categories.
- `test_wokeai.py`: A script to test the WOKEAI dataset on different LLMs and analyze their responses.

## How to Use

1. **Dataset Access**: Open the `wokeai_dataset.xlsx` file to explore the curated prompts and their corresponding categories.
2. **Testing Script**: Use the `test_wokeai.py` script to test the dataset on various LLMs. Ensure you have the necessary dependencies installed.
3. **Evaluation**: Follow the methodology outlined to evaluate the responses generated by the models.

## Contact

For any inquiries or further information, please contact the project lead at [mf@matteoflora.com].

We believe WOKEAI will play a pivotal role in advancing the ethical alignment and societal awareness of AI systems. Your feedback and contributions are highly valued as we continue to refine and expand this crucial resource.

